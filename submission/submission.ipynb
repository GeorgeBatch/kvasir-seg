{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # select device for training, i.e. gpu or cpu\n",
    "\n",
    "_size = 256, 256\n",
    "resize = transforms.Resize(_size, interpolation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOITS_PATH = \"../checkpoints\"\n",
    "TEST_DATASET_PATH = \"../data/test/images\"\n",
    "MASK_PATH = \"../predictions_test\"\n",
    "\n",
    "# # Set path to test dataset (Like in the instructions)\n",
    "# CHECKPOITS_PATH = \"\"\n",
    "# TEST_DATASET_PATH = \"/medico2020\"\n",
    "# MASK_PATH = \"/mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model. In this case we're using a basic UNet architecture. The output channel for segmentation should be equal to number of classes we want to segment the image into. For a binary segmentation, this is a value of 1.\n",
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def conv_block(self, channel_in, channel_out):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(channel_in, channel_out, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(channel_out),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(channel_out, channel_out, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(channel_out),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def __init__(self, channel_in, channel_out, bilinear=None):\n",
    "        super(UNet, self).__init__()\n",
    "        self.channel_in = channel_in\n",
    "        self.channel_out = channel_out\n",
    "        \n",
    "        # initial convolutional block\n",
    "        self.initial = self.conv_block(channel_in, 64)\n",
    "        \n",
    "        # encoder layers\n",
    "        self.down0 = self.conv_block(64, 128)\n",
    "        self.down1 = self.conv_block(128, 256)\n",
    "        self.down2 = self.conv_block(256, 512)\n",
    "        self.down3 = self.conv_block(512, 1024)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.up0_0 = torch.nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up0_1 = self.conv_block(1024, 512)\n",
    "        self.up1_0 = torch.nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up1_1 = self.conv_block(512, 256)\n",
    "        self.up2_0 = torch.nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up2_1 = self.conv_block(256, 128)\n",
    "        self.up3_0 = torch.nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up3_1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # final layer before output\n",
    "        self.final = torch.nn.Conv2d(64, channel_out, kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"Forward pass\"\n",
    "        x_in= self.initial(x)\n",
    "        enc0 = self.down0(torch.nn.MaxPool2d(2)(x_in))\n",
    "        enc1 = self.down1(torch.nn.MaxPool2d(2)(enc0))\n",
    "        enc2 = self.down2(torch.nn.MaxPool2d(2)(enc1))\n",
    "        enc3 = self.down3(torch.nn.MaxPool2d(2)(enc2))\n",
    "        \n",
    "        dec0 = self.up0_0(enc3)\n",
    "        diff0 = torch.FloatTensor(list(enc2.size())[2:]) - torch.FloatTensor(list(dec0.shape))[2:]\n",
    "        dec0 = torch.nn.functional.pad(dec0, (int((diff0/2).floor()[0]), int((diff0/2).ceil()[0]), int((diff0/2).floor()[1]), int((diff0/2).ceil()[1])))\n",
    "        dec0 = self.up0_1(torch.cat((enc2, dec0), dim=1))\n",
    "\n",
    "        dec1 = self.up1_0(dec0)\n",
    "        diff1 = torch.FloatTensor(list(enc1.size())[2:]) - torch.FloatTensor(list(dec1.shape))[2:]\n",
    "        dec1 = torch.nn.functional.pad(dec1, (int((diff1/2).floor()[0]), int((diff1/2).ceil()[0]), int((diff1/2).floor()[1]), int((diff1/2).ceil()[1])))\n",
    "        dec1 = self.up1_1(torch.cat((enc1, dec1), dim=1))\n",
    "\n",
    "        dec2 = self.up2_0(dec1)\n",
    "        diff2 = torch.FloatTensor(list(enc0.size())[2:]) - torch.FloatTensor(list(dec2.shape))[2:]\n",
    "        dec2 = torch.nn.functional.pad(dec2, (int((diff2/2).floor()[0]), int((diff2/2).ceil()[0]), int((diff2/2).floor()[1]), int((diff2/2).ceil()[1])))\n",
    "        dec2 = self.up2_1(torch.cat((enc0, dec2), dim=1))\n",
    "\n",
    "        dec3 = self.up3_0(dec2)\n",
    "        diff3 = torch.FloatTensor(list(x.size())[2:]) - torch.FloatTensor(list(dec3.shape))[2:]\n",
    "        dec3 = torch.nn.functional.pad(dec3, (int((diff3/2).floor()[0]), int((diff3/2).ceil()[0]), int((diff3/2).floor()[1]), int((diff3/2).ceil()[1])))\n",
    "        dec3 = self.up3_1(torch.cat((x_in, dec3), dim=1))\n",
    "        \n",
    "        x_out = self.final(dec3) # ? no activation here\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'UNet_IoULoss_baseline'\n",
    "chpt_file_name = \"ckpt_\" + model_name + \".pth\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = UNet(channel_in=3, channel_out=1)\n",
    "model = model.to(DEVICE) # load model to DEVICE\n",
    "\n",
    "\n",
    "# load best weights and put into the evaluation mode\n",
    "chpt_file_path  = os.path.join(CHECKPOITS_PATH, chpt_file_name)\n",
    "model.load_state_dict(torch.load(chpt_file_path)['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckda5qdj900053a5sm6zg4bwb.jpg - 0.0089638233\n",
      "ckda142i5000h3a5ssv9kauan.jpg - 0.0039613247\n",
      "ckdaa12yj000r3a5srr4ahcg2.jpg - 0.0039975643\n",
      "ckcaidxum2xrf0y6g0329hw80.jpg - 0.0039637089\n",
      "ckda0kbde00083a5s2296juqy.jpg - 0.0042879581\n",
      "ckda22o7b000v3a5s6zjzj7o3.jpg - 0.0042531490\n",
      "ckda9x11x000h3a5st1g20mrf.jpg - 0.0038948059\n",
      "ckda1jqsp000o3a5s5lh3pkdn.jpg - 0.0038816929\n",
      "ckcbqi8ry27wq0y7m7xqmecor.jpg - 0.0038597584\n",
      "ckd8sxdyn000a3b5sclphcakf.jpg - 0.0037970543\n",
      "ckdaa001p000n3a5shzakc3ar.jpg - 0.0038394928\n",
      "ckcbpz4vz28i70y5p347j9b4a.jpg - 0.0038213730\n",
      "ckda1ehes000j3a5sr74zgivg.jpg - 0.0037589073\n",
      "ckcbpmwgb267j0y5pcv7404dq.jpg - 0.0038518906\n",
      "ckda1j0sy000n3a5stotfjqpc.jpg - 0.0038666725\n",
      "ckcbsv8zd2i010y6g6te29eg7.jpg - 0.0038664341\n",
      "ckcbt2pbv2ptl0y5p7xea6hg3.jpg - 0.0039634705\n",
      "ckcbm3tjn0dyu0y4h4kbld9ro.jpg - 0.0038628578\n",
      "ckdaa0oyd000q3a5sabbv22b0.jpg - 0.0038604736\n",
      "ckcbqhgfw27qx0y7mbi0l9wn4.jpg - 0.0038928986\n",
      "ckcbswp262i6n0y6g2krjfhdb.jpg - 0.0038199425\n",
      "ckcbt0asc2k520y5n4e5i8c9y.jpg - 0.0038850307\n",
      "ckda0hpik00053a5s3fiv5ry9.jpg - 0.0038852692\n",
      "ckda0qhcw000e3a5s654bhalg.jpg - 0.0039820671\n",
      "ckda1yeh7000u3a5s37trez74.jpg - 0.0039100647\n",
      "ckda5xk19000f3a5s6rpp4xlq.jpg - 0.0037832260\n",
      "ckda0i0f000063a5s28oczcwf.jpg - 0.0039217472\n",
      "ckcbqcksy2avk0y5p48zm1cyx.jpg - 0.0039288998\n",
      "ckd8u48vp000g3b5s3c55bvoj.jpg - 0.0042538643\n",
      "ckcbltunv1g4g0y7m84o5fvix.jpg - 0.0041434765\n",
      "ckcbqj0as28110y7meq1bhdw6.jpg - 0.0038499832\n",
      "ckcbpx29q242a0y7m3hmb7j8f.jpg - 0.0037844181\n",
      "ckd8u5qw3000i3b5sgzq7ce3l.jpg - 0.0038626194\n",
      "ckda0e2zr00023a5sm4rhyu22.jpg - 0.0038182735\n",
      "ckcbqfw1224lo0y6g8zwq8w3j.jpg - 0.0037670135\n",
      "ckcbm9wu21iag0y7m64rm6oz7.jpg - 0.0038375854\n",
      "ckda0guyf00043a5sru4xeu0y.jpg - 0.0038120747\n",
      "ckcai75gy0rwm0y47f6zm6c4y.jpg - 0.0037741661\n",
      "ckcbm7flj1fid0y6gcsmoeipg.jpg - 0.0037887096\n",
      "ckcbkvuh01agn0y5n2sqs4vhy.jpg - 0.0040223598\n",
      "ckda4xclk001a3a5svnxcascb.jpg - 0.0038998127\n",
      "ckd8rln2j00073b5s5t3jb0ef.jpg - 0.0042111874\n",
      "ckd8rnczu00093b5s3nlrjr2p.jpg - 0.0041642189\n",
      "ckcbstv7d0cu90z4hb04sb4ly.jpg - 0.0038743019\n",
      "ckda5xyr4000g3a5sc1dpzwya.jpg - 0.0038819313\n",
      "ckd8u31cm000e3b5s3mbgboro.jpg - 0.0038323402\n",
      "ckda4t1yt00143a5sxkqz1pn7.jpg - 0.0038485527\n",
      "ckd8tucza00033b5sm65huh8r.jpg - 0.0038084984\n",
      "ckcblygox1fjn0y5n4t9w76xr.jpg - 0.0038342476\n",
      "ckcblngeo1jai0y5p6psactck.jpg - 0.0038716793\n",
      "ckda5tjlf00083a5ssc8d2wcx.jpg - 0.0038237572\n",
      "ckdaa07mq000o3a5s2y4iufmb.jpg - 0.0044214725\n",
      "ckcbqdu8g257l0y5nf7nrf23y.jpg - 0.0038566589\n",
      "ckcblv2mg0cnv0y6h6g71f1wm.jpg - 0.0038359165\n",
      "ckda9yzdh000l3a5sacifrd8r.jpg - 0.0039513111\n",
      "ckcblfowe0abp0y4hf95z4q6o.jpg - 0.0039248466\n",
      "ckda0d2uz00013a5s4m6o37c6.jpg - 0.0038001537\n",
      "ckd8tyc3z00093b5s2p9b0ges.jpg - 0.0039319992\n",
      "ckdaa0faj000p3a5s5mw2smrd.jpg - 0.0038869381\n",
      "ckd8synvm000d3b5shaneypja.jpg - 0.0038418770\n",
      "ckda1ifr7000m3a5sgm7gf2kv.jpg - 0.0038015842\n",
      "ckd8tnm3g000h3b5s1rxnjsq3.jpg - 0.0038957596\n",
      "ckcbq9p5c054t0y4h3w5n1f9g.jpg - 0.0037996769\n",
      "ckd8sxr2u000b3b5ssko8d40l.jpg - 0.0037798882\n",
      "ckda4okxk00103a5s2mfx4afr.jpg - 0.0038013458\n",
      "ckda1tdd8000r3a5sx5xvm4kv.jpg - 0.0037999153\n",
      "ckd8tx25100073b5sn7cjx32x.jpg - 0.0037467480\n",
      "ckd8strm900053b5srwqcah9s.jpg - 0.0040664673\n",
      "ckda58aul00003a5spqcnvw7x.jpg - 0.0039501190\n",
      "ckda0rcqm000f3a5s36keoqwd.jpg - 0.0038669109\n",
      "ckd8rkeea00063b5segvd2va3.jpg - 0.0038924217\n",
      "ckd8tvw6j00053b5swagqipc1.jpg - 0.0039315224\n",
      "ckcbkgdfw1djg0y5p7qu9bmcy.jpg - 0.0038974285\n",
      "ckda5q38x00043a5shgg1bffc.jpg - 0.0038819313\n",
      "ckd8u26a5000d3b5sa5f1vgiz.jpg - 0.0038387775\n",
      "ckd8tq1xr000j3b5s1kn6vx34.jpg - 0.0038344860\n",
      "ckd8sz9ut000e3b5s6vs09c0c.jpg - 0.0038795471\n",
      "ckda4l7w7000w3a5s16rryuzy.jpg - 0.0038263798\n",
      "ckd8swq2100093b5s1zjkgj4b.jpg - 0.0038414001\n",
      "ckd8u4ogu000h3b5s6m9nafxq.jpg - 0.0043420792\n",
      "ckd8toa0f000i3b5swbpasudq.jpg - 0.0039999485\n",
      "ckd8tspte00003b5seb3ryptl.jpg - 0.0038475990\n",
      "ckcbqb2xc24oe0y5nedoo8uar.jpg - 0.0039193630\n",
      "ckda5i7zd00033a5se01mcaf3.jpg - 0.0039024353\n",
      "ckda5v1qj000b3a5sk9jrmjh5.jpg - 0.0038836002\n",
      "ckd8ttzeo00023b5sfro24eom.jpg - 0.0039095879\n",
      "ckd8tuxn000043b5s8bwtvcom.jpg - 0.0038356781\n",
      "ckda9xc7j000i3a5shbnuqx4l.jpg - 0.0038740635\n",
      "ckda4vnv400173a5stmwdirfa.jpg - 0.0038943291\n",
      "ckd8u3pst000f3b5swm6cb3es.jpg - 0.0037901402\n",
      "ckda044sr00003a5s0u2f22il.jpg - 0.0038340092\n",
      "ckd8sy9sg000c3b5sgrphj4u8.jpg - 0.0038232803\n",
      "ckcblrxjs1dbr0y6g0i0qgy3g.jpg - 0.0037946701\n",
      "ckcbkz2hz1avm0y5n69y6c3hc.jpg - 0.0037903786\n",
      "ckcbprh7h270x0y5p615bdses.jpg - 0.0037837029\n",
      "ckcbpttsk024l0y4h6d443eg5.jpg - 0.0038011074\n",
      "ckcblq99h0bzq0y4hddj432v9.jpg - 0.0037789345\n",
      "ckcbpuklk27lh0y5p57ir7up6.jpg - 0.0044691563\n",
      "ckd8u03ax000b3b5s6wlo2oa1.jpg - 0.0038635731\n",
      "ckcbt6mj60bap0y6h330q4c68.jpg - 0.0038890839\n",
      "ckdaa1wf9000s3a5sk52a8v3a.jpg - 0.0038337708\n",
      "ckda4psr900113a5s4wv12z5g.jpg - 0.0038878918\n",
      "ckda0l4kk000a3a5s3qh2vmjp.jpg - 0.0038516521\n",
      "ckda58hqd00013a5sfw1h65tx.jpg - 0.0038688183\n",
      "ckda5gyul00023a5syjkqr1yc.jpg - 0.0038735867\n",
      "ckd8tmpp3000g3b5scbgr51m8.jpg - 0.0038747787\n",
      "ckcbt1akv0dxo0z4h394xb3l3.jpg - 0.0038797855\n",
      "ckd8sr33b00003b5sl6899a8l.jpg - 0.0037910938\n",
      "ckcbq81iy240i0y5n8xiodmnm.jpg - 0.0038361549\n",
      "ckcbq2a7722d90y6g4h9rd9gw.jpg - 0.0038938522\n",
      "ckd8stdnx00043b5sxun8ewkv.jpg - 0.0038754940\n",
      "ckcbm6dni1fcc0y6ggt5c7hlb.jpg - 0.0038750172\n",
      "ckcbpof9w1ztu0y6g66craon3.jpg - 0.0039103031\n",
      "ckda1xv1r000t3a5s3mw0kj98.jpg - 0.0039482117\n",
      "ckcbsxxri0dhr0z4h3w6p9bxt.jpg - 0.0038805008\n",
      "ckcbpwbcz27y50y5p99aud939.jpg - 0.0038595200\n",
      "ckda1ddcv000i3a5sl3k693l2.jpg - 0.0038437843\n",
      "ckda4xqus001b3a5s30zk3wci.jpg - 0.0037891865\n",
      "ckd8rmjd700083b5sk7ajpzf6.jpg - 0.0037744045\n",
      "ckcbsytaq0dm40z4hc7zx5s2p.jpg - 0.0038745403\n",
      "ckda0punw000d3a5sfa07x5je.jpg - 0.0037879944\n",
      "ckda5wgcv000d3a5s3804l420.jpg - 0.0041260719\n",
      "ckda4s52800133a5s48fg91pt.jpg - 0.0039494038\n",
      "ckda0ksgq00093a5se2y6g9h1.jpg - 0.0037834644\n",
      "ckcblj30z1ei40y7m1w963ryj.jpg - 0.0038821697\n",
      "ckda1fpc5000l3a5s17a45xql.jpg - 0.0039255619\n",
      "ckd8txnqo00083b5spbqvehzd.jpg - 0.0039362907\n",
      "ckd8ssoan00033b5sdjgxl66l.jpg - 0.0038669109\n",
      "ckcai9nma2xig0y6g595c7mtj.jpg - 0.0038528442\n",
      "ckcbpq9ck01im0y6haj4bca8h.jpg - 0.0038719177\n",
      "ckda5txx200093a5s16i2y97u.jpg - 0.0039117336\n",
      "ckd8u18d7000c3b5suod5aqf2.jpg - 0.0037395954\n",
      "ckda5rqvv00073a5sjxu7peen.jpg - 0.0038950443\n",
      "ckda0j24m00073a5s1oruar1e.jpg - 0.0042257309\n",
      "ckda1x6ce000s3a5sb9h33n12.jpg - 0.0049593449\n",
      "ckcbkx23f1bvd0y7m823u8lb6.jpg - 0.0045812130\n",
      "ckcblwsw91koh0y5pe2pt84hl.jpg - 0.0045831203\n",
      "ckda1f8q9000k3a5st2222ay7.jpg - 0.0045754910\n",
      "ckd8srbmv00013b5sliek3ejo.jpg - 0.0045070648\n",
      "ckcbt3uee2lwb0y7m5va0havv.jpg - 0.0044786930\n",
      "ckda9y9dd000j3a5sii08df1n.jpg - 0.0045070648\n",
      "ckda4r0w000123a5sp7v2iyem.jpg - 0.0045990944\n",
      "ckd8sun6y00063b5swzdd3fd8.jpg - 0.0045838356\n",
      "ckda5wz53000e3a5s4v8to66t.jpg - 0.0046248436\n",
      "ckcbt5sqf2kpw0y5nhh213g8i.jpg - 0.0045647621\n",
      "ckd8swai400083b5sn1693d25.jpg - 0.0045807362\n",
      "ckcbq43s523fe0y5n126g6w5h.jpg - 0.0046000481\n",
      "ckd8sv8ds00073b5scw72l1dy.jpg - 0.0046143532\n",
      "ckda0seg1000g3a5s43lgah9e.jpg - 0.0046339035\n",
      "ckda1spnc000q3a5srfxlvwce.jpg - 0.0046553612\n",
      "ckd8ttjwc00013b5s33m1jgq2.jpg - 0.0049140453\n",
      "ckcbq0gs703hv0y4h735ha581.jpg - 0.0047159195\n",
      "ckda5ue81000a3a5sqapb5u41.jpg - 0.0045819283\n",
      "ckda4mi4r000y3a5sln7mxclv.jpg - 0.0045785904\n",
      "ckda0oaty000c3a5sz6zigemv.jpg - 0.0044922829\n",
      "ckd8twk1a00063b5slocqudcl.jpg - 0.0045249462\n",
      "ckcaibt572pxu0y6fazrxcc4f.jpg - 0.0045077801\n",
      "ckda9yrip000k3a5sj7jkyh1q.jpg - 0.0045342445\n",
      "ckda9zgi9000m3a5sof671qjh.jpg - 0.0046365261\n",
      "ckd8srxq500023b5ssndncx7o.jpg - 0.0047485828\n",
      "\n",
      "Mean FPS:  247.29609150589323\n"
     ]
    }
   ],
   "source": [
    "time_taken = []\n",
    "\n",
    "model.eval() # enter inference/evaluation mode \n",
    "for name in os.listdir(TEST_DATASET_PATH):\n",
    "    path_img = os.path.join(TEST_DATASET_PATH, name)\n",
    "        \n",
    "    img = imageio.imread(path_img) / 255\n",
    "    \n",
    "    # record shape to revert to \n",
    "    H, W, _ = img.shape\n",
    "    resize_back = transforms.Resize((H, W), interpolation=0)\n",
    "    \n",
    "    # convert to Tensors and fix the dimentions (Pytorch uses the channels in the first dimension)\n",
    "    img = torch.FloatTensor(np.transpose(img, [2, 0 ,1])).unsqueeze(0) \n",
    "    \n",
    "    # resize for the model\n",
    "    img = resize(img)\n",
    "    \n",
    "    # put on the GPU\n",
    "    img = img.to(DEVICE)\n",
    "       \n",
    "    # we do not need to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        # Start time\n",
    "        start_time = time.time()\n",
    "        ## Prediction\n",
    "        pred = model(img)\n",
    "        # End timer\n",
    "        end_time = time.time() - start_time\n",
    "\n",
    "    time_taken.append(end_time)\n",
    "    print(\"{} - {:.10f}\".format(name, end_time))\n",
    "        \n",
    "    \n",
    "    # resize back, nearest interpolation, since it's a mask\n",
    "    pred = resize_back(pred)\n",
    "    # put on cpu\n",
    "    pred = pred.cpu()\n",
    "        \n",
    "    # remove channel: BATCH x 1 x H x W => BATCH x H x W\n",
    "    pred = pred.squeeze(1)\n",
    "        \n",
    "    # comment out if your model contains a sigmoid or equivalent activation layer\n",
    "    pred = torch.sigmoid(pred)\n",
    "    # thresholding since that's how we will make predictions on new imputs\n",
    "    pred = pred > 0.5 \n",
    "    # remove BATCH => H x W\n",
    "    pred = pred.squeeze(0)\n",
    "    # convert to correct type\n",
    "    pred = pred.numpy().astype(np.float32)\n",
    "    # revert to standard intensities\n",
    "    pred = pred * 255.0\n",
    "    # save\n",
    "    pred_path = os.path.join(MASK_PATH, name)\n",
    "    cv2.imwrite(pred_path, pred)\n",
    "\n",
    "\n",
    "mean_time_taken = np.mean(time_taken)\n",
    "mean_fps = 1/mean_time_taken\n",
    "print(\"\\nMean FPS: \", mean_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
