{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # select device for training, i.e. gpu or cpu\n",
    "_size = 256, 256\n",
    "resize = transforms.Resize(_size, interpolation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model. In this case we're using a basic UNet architecture. The output channel for segmentation should be equal to number of classes we want to segment the image into. For a binary segmentation, this is a value of 1.\n",
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def conv_block(self, channel_in, channel_out):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(channel_in, channel_out, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(channel_out),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(channel_out, channel_out, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(channel_out),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def __init__(self, channel_in, channel_out, bilinear=None):\n",
    "        super(UNet, self).__init__()\n",
    "        self.channel_in = channel_in\n",
    "        self.channel_out = channel_out\n",
    "        \n",
    "        # initial convolutional block\n",
    "        self.initial = self.conv_block(channel_in, 64)\n",
    "        \n",
    "        # encoder layers\n",
    "        self.down0 = self.conv_block(64, 128)\n",
    "        self.down1 = self.conv_block(128, 256)\n",
    "        self.down2 = self.conv_block(256, 512)\n",
    "        self.down3 = self.conv_block(512, 1024)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.up0_0 = torch.nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up0_1 = self.conv_block(1024, 512)\n",
    "        self.up1_0 = torch.nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up1_1 = self.conv_block(512, 256)\n",
    "        self.up2_0 = torch.nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up2_1 = self.conv_block(256, 128)\n",
    "        self.up3_0 = torch.nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up3_1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # final layer before output\n",
    "        self.final = torch.nn.Conv2d(64, channel_out, kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"Forward pass\"\n",
    "        x_in= self.initial(x)\n",
    "        enc0 = self.down0(torch.nn.MaxPool2d(2)(x_in))\n",
    "        enc1 = self.down1(torch.nn.MaxPool2d(2)(enc0))\n",
    "        enc2 = self.down2(torch.nn.MaxPool2d(2)(enc1))\n",
    "        enc3 = self.down3(torch.nn.MaxPool2d(2)(enc2))\n",
    "        \n",
    "        dec0 = self.up0_0(enc3)\n",
    "        diff0 = torch.FloatTensor(list(enc2.size())[2:]) - torch.FloatTensor(list(dec0.shape))[2:]\n",
    "        dec0 = torch.nn.functional.pad(dec0, (int((diff0/2).floor()[0]), int((diff0/2).ceil()[0]), int((diff0/2).floor()[1]), int((diff0/2).ceil()[1])))\n",
    "        dec0 = self.up0_1(torch.cat((enc2, dec0), dim=1))\n",
    "\n",
    "        dec1 = self.up1_0(dec0)\n",
    "        diff1 = torch.FloatTensor(list(enc1.size())[2:]) - torch.FloatTensor(list(dec1.shape))[2:]\n",
    "        dec1 = torch.nn.functional.pad(dec1, (int((diff1/2).floor()[0]), int((diff1/2).ceil()[0]), int((diff1/2).floor()[1]), int((diff1/2).ceil()[1])))\n",
    "        dec1 = self.up1_1(torch.cat((enc1, dec1), dim=1))\n",
    "\n",
    "        dec2 = self.up2_0(dec1)\n",
    "        diff2 = torch.FloatTensor(list(enc0.size())[2:]) - torch.FloatTensor(list(dec2.shape))[2:]\n",
    "        dec2 = torch.nn.functional.pad(dec2, (int((diff2/2).floor()[0]), int((diff2/2).ceil()[0]), int((diff2/2).floor()[1]), int((diff2/2).ceil()[1])))\n",
    "        dec2 = self.up2_1(torch.cat((enc0, dec2), dim=1))\n",
    "\n",
    "        dec3 = self.up3_0(dec2)\n",
    "        diff3 = torch.FloatTensor(list(x.size())[2:]) - torch.FloatTensor(list(dec3.shape))[2:]\n",
    "        dec3 = torch.nn.functional.pad(dec3, (int((diff3/2).floor()[0]), int((diff3/2).ceil()[0]), int((diff3/2).floor()[1]), int((diff3/2).ceil()[1])))\n",
    "        dec3 = self.up3_1(torch.cat((x_in, dec3), dim=1))\n",
    "        \n",
    "        x_out = self.final(dec3) # ? no activation here\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'UNet_IoULoss_baseline'\n",
    "\n",
    "# Instantiate the model\n",
    "model = UNet(channel_in=3, channel_out=1)\n",
    "model = model.to(DEVICE) # load model to DEVICE\n",
    "\n",
    "# load best weights and put into the evaluation mode\n",
    "model.load_state_dict(torch.load('ckpt_UNet_IoULoss_baseline.pth')['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckda5qdj900053a5sm6zg4bwb.jpg - 0.0042421818\n",
      "ckda142i5000h3a5ssv9kauan.jpg - 0.0038664341\n",
      "ckdaa12yj000r3a5srr4ahcg2.jpg - 0.0038087368\n",
      "ckcaidxum2xrf0y6g0329hw80.jpg - 0.0038712025\n",
      "ckda0kbde00083a5s2296juqy.jpg - 0.0041453838\n",
      "ckda22o7b000v3a5s6zjzj7o3.jpg - 0.0039129257\n",
      "ckda9x11x000h3a5st1g20mrf.jpg - 0.0037140846\n",
      "ckda1jqsp000o3a5s5lh3pkdn.jpg - 0.0037775040\n",
      "ckcbqi8ry27wq0y7m7xqmecor.jpg - 0.0035574436\n",
      "ckd8sxdyn000a3b5sclphcakf.jpg - 0.0036368370\n",
      "ckdaa001p000n3a5shzakc3ar.jpg - 0.0035805702\n",
      "ckcbpz4vz28i70y5p347j9b4a.jpg - 0.0036525726\n",
      "ckda1ehes000j3a5sr74zgivg.jpg - 0.0035729408\n",
      "ckcbpmwgb267j0y5pcv7404dq.jpg - 0.0037393570\n",
      "ckda1j0sy000n3a5stotfjqpc.jpg - 0.0035853386\n",
      "ckcbsv8zd2i010y6g6te29eg7.jpg - 0.0035734177\n",
      "ckcbt2pbv2ptl0y5p7xea6hg3.jpg - 0.0036356449\n",
      "ckcbm3tjn0dyu0y4h4kbld9ro.jpg - 0.0036866665\n",
      "ckdaa0oyd000q3a5sabbv22b0.jpg - 0.0035820007\n",
      "ckcbqhgfw27qx0y7mbi0l9wn4.jpg - 0.0035364628\n",
      "ckcbswp262i6n0y6g2krjfhdb.jpg - 0.0036857128\n",
      "ckcbt0asc2k520y5n4e5i8c9y.jpg - 0.0035896301\n",
      "ckda0hpik00053a5s3fiv5ry9.jpg - 0.0035653114\n",
      "ckda0qhcw000e3a5s654bhalg.jpg - 0.0037703514\n",
      "ckda1yeh7000u3a5s37trez74.jpg - 0.0036232471\n",
      "ckda5xk19000f3a5s6rpp4xlq.jpg - 0.0036506653\n",
      "ckda0i0f000063a5s28oczcwf.jpg - 0.0043084621\n",
      "ckcbqcksy2avk0y5p48zm1cyx.jpg - 0.0036797523\n",
      "ckd8u48vp000g3b5s3c55bvoj.jpg - 0.0039551258\n",
      "ckcbltunv1g4g0y7m84o5fvix.jpg - 0.0038537979\n",
      "ckcbqj0as28110y7meq1bhdw6.jpg - 0.0035915375\n",
      "ckcbpx29q242a0y7m3hmb7j8f.jpg - 0.0035908222\n",
      "ckd8u5qw3000i3b5sgzq7ce3l.jpg - 0.0036122799\n",
      "ckda0e2zr00023a5sm4rhyu22.jpg - 0.0035042763\n",
      "ckcbqfw1224lo0y6g8zwq8w3j.jpg - 0.0036547184\n",
      "ckcbm9wu21iag0y7m64rm6oz7.jpg - 0.0036430359\n",
      "ckda0guyf00043a5sru4xeu0y.jpg - 0.0035688877\n",
      "ckcai75gy0rwm0y47f6zm6c4y.jpg - 0.0036208630\n",
      "ckcbm7flj1fid0y6gcsmoeipg.jpg - 0.0036876202\n",
      "ckcbkvuh01agn0y5n2sqs4vhy.jpg - 0.0037145615\n",
      "ckda4xclk001a3a5svnxcascb.jpg - 0.0037343502\n",
      "ckd8rln2j00073b5s5t3jb0ef.jpg - 0.0040819645\n",
      "ckd8rnczu00093b5s3nlrjr2p.jpg - 0.0038452148\n",
      "ckcbstv7d0cu90z4hb04sb4ly.jpg - 0.0036389828\n",
      "ckda5xyr4000g3a5sc1dpzwya.jpg - 0.0037128925\n",
      "ckd8u31cm000e3b5s3mbgboro.jpg - 0.0037231445\n",
      "ckda4t1yt00143a5sxkqz1pn7.jpg - 0.0037939548\n",
      "ckd8tucza00033b5sm65huh8r.jpg - 0.0038001537\n",
      "ckcblygox1fjn0y5n4t9w76xr.jpg - 0.0038151741\n",
      "ckcblngeo1jai0y5p6psactck.jpg - 0.0037071705\n",
      "ckda5tjlf00083a5ssc8d2wcx.jpg - 0.0037910938\n",
      "ckdaa07mq000o3a5s2y4iufmb.jpg - 0.0037376881\n",
      "ckcbqdu8g257l0y5nf7nrf23y.jpg - 0.0037646294\n",
      "ckcblv2mg0cnv0y6h6g71f1wm.jpg - 0.0038814545\n",
      "ckda9yzdh000l3a5sacifrd8r.jpg - 0.0038778782\n",
      "ckcblfowe0abp0y4hf95z4q6o.jpg - 0.0038602352\n",
      "ckda0d2uz00013a5s4m6o37c6.jpg - 0.0037908554\n",
      "ckd8tyc3z00093b5s2p9b0ges.jpg - 0.0037715435\n",
      "ckdaa0faj000p3a5s5mw2smrd.jpg - 0.0038692951\n",
      "ckd8synvm000d3b5shaneypja.jpg - 0.0040929317\n",
      "ckda1ifr7000m3a5sgm7gf2kv.jpg - 0.0038385391\n",
      "ckd8tnm3g000h3b5s1rxnjsq3.jpg - 0.0038015842\n",
      "ckcbq9p5c054t0y4h3w5n1f9g.jpg - 0.0038399696\n",
      "ckd8sxr2u000b3b5ssko8d40l.jpg - 0.0037434101\n",
      "ckda4okxk00103a5s2mfx4afr.jpg - 0.0037715435\n",
      "ckda1tdd8000r3a5sx5xvm4kv.jpg - 0.0039169788\n",
      "ckd8tx25100073b5sn7cjx32x.jpg - 0.0038115978\n",
      "ckd8strm900053b5srwqcah9s.jpg - 0.0038444996\n",
      "ckda58aul00003a5spqcnvw7x.jpg - 0.0038621426\n",
      "ckda0rcqm000f3a5s36keoqwd.jpg - 0.0040206909\n",
      "ckd8rkeea00063b5segvd2va3.jpg - 0.0037758350\n",
      "ckd8tvw6j00053b5swagqipc1.jpg - 0.0038185120\n",
      "ckcbkgdfw1djg0y5p7qu9bmcy.jpg - 0.0037901402\n",
      "ckda5q38x00043a5shgg1bffc.jpg - 0.0038697720\n",
      "ckd8u26a5000d3b5sa5f1vgiz.jpg - 0.0037946701\n",
      "ckd8tq1xr000j3b5s1kn6vx34.jpg - 0.0038723946\n",
      "ckd8sz9ut000e3b5s6vs09c0c.jpg - 0.0038373470\n",
      "ckda4l7w7000w3a5s16rryuzy.jpg - 0.0037112236\n",
      "ckd8swq2100093b5s1zjkgj4b.jpg - 0.0038328171\n",
      "ckd8u4ogu000h3b5s6m9nafxq.jpg - 0.0054297447\n",
      "ckd8toa0f000i3b5swbpasudq.jpg - 0.0040624142\n",
      "ckd8tspte00003b5seb3ryptl.jpg - 0.0039069653\n",
      "ckcbqb2xc24oe0y5nedoo8uar.jpg - 0.0038328171\n",
      "ckda5i7zd00033a5se01mcaf3.jpg - 0.0038537979\n",
      "ckda5v1qj000b3a5sk9jrmjh5.jpg - 0.0037181377\n",
      "ckd8ttzeo00023b5sfro24eom.jpg - 0.0037398338\n",
      "ckd8tuxn000043b5s8bwtvcom.jpg - 0.0038399696\n",
      "ckda9xc7j000i3a5shbnuqx4l.jpg - 0.0038609505\n",
      "ckda4vnv400173a5stmwdirfa.jpg - 0.0037405491\n",
      "ckd8u3pst000f3b5swm6cb3es.jpg - 0.0038881302\n",
      "ckda044sr00003a5s0u2f22il.jpg - 0.0038714409\n",
      "ckd8sy9sg000c3b5sgrphj4u8.jpg - 0.0037496090\n",
      "ckcblrxjs1dbr0y6g0i0qgy3g.jpg - 0.0038185120\n",
      "ckcbkz2hz1avm0y5n69y6c3hc.jpg - 0.0038535595\n",
      "ckcbprh7h270x0y5p615bdses.jpg - 0.0039975643\n",
      "ckcbpttsk024l0y4h6d443eg5.jpg - 0.0039191246\n",
      "ckcblq99h0bzq0y4hddj432v9.jpg - 0.0037875175\n",
      "ckcbpuklk27lh0y5p57ir7up6.jpg - 0.0037901402\n",
      "ckd8u03ax000b3b5s6wlo2oa1.jpg - 0.0039119720\n",
      "ckcbt6mj60bap0y6h330q4c68.jpg - 0.0037705898\n",
      "ckdaa1wf9000s3a5sk52a8v3a.jpg - 0.0037484169\n",
      "ckda4psr900113a5s4wv12z5g.jpg - 0.0038390160\n",
      "ckda0l4kk000a3a5s3qh2vmjp.jpg - 0.0041930676\n",
      "ckda58hqd00013a5sfw1h65tx.jpg - 0.0038185120\n",
      "ckda5gyul00023a5syjkqr1yc.jpg - 0.0037987232\n",
      "ckd8tmpp3000g3b5scbgr51m8.jpg - 0.0037388802\n",
      "ckcbt1akv0dxo0z4h394xb3l3.jpg - 0.0038173199\n",
      "ckd8sr33b00003b5sl6899a8l.jpg - 0.0037860870\n",
      "ckcbq81iy240i0y5n8xiodmnm.jpg - 0.0038249493\n",
      "ckcbq2a7722d90y6g4h9rd9gw.jpg - 0.0038430691\n",
      "ckd8stdnx00043b5sxun8ewkv.jpg - 0.0038146973\n",
      "ckcbm6dni1fcc0y6ggt5c7hlb.jpg - 0.0037860870\n",
      "ckcbpof9w1ztu0y6g66craon3.jpg - 0.0037810802\n",
      "ckda1xv1r000t3a5s3mw0kj98.jpg - 0.0037565231\n",
      "ckcbsxxri0dhr0z4h3w6p9bxt.jpg - 0.0039045811\n",
      "ckcbpwbcz27y50y5p99aud939.jpg - 0.0038177967\n",
      "ckda1ddcv000i3a5sl3k693l2.jpg - 0.0037906170\n",
      "ckda4xqus001b3a5s30zk3wci.jpg - 0.0038759708\n",
      "ckd8rmjd700083b5sk7ajpzf6.jpg - 0.0037660599\n",
      "ckcbsytaq0dm40z4hc7zx5s2p.jpg - 0.0038270950\n",
      "ckda0punw000d3a5sfa07x5je.jpg - 0.0038273335\n",
      "ckda5wgcv000d3a5s3804l420.jpg - 0.0051016808\n",
      "ckda4s52800133a5s48fg91pt.jpg - 0.0048427582\n",
      "ckda0ksgq00093a5se2y6g9h1.jpg - 0.0045096874\n",
      "ckcblj30z1ei40y7m1w963ryj.jpg - 0.0044341087\n",
      "ckda1fpc5000l3a5s17a45xql.jpg - 0.0045611858\n",
      "ckd8txnqo00083b5spbqvehzd.jpg - 0.0045580864\n",
      "ckd8ssoan00033b5sdjgxl66l.jpg - 0.0045480728\n",
      "ckcai9nma2xig0y6g595c7mtj.jpg - 0.0044355392\n",
      "ckcbpq9ck01im0y6haj4bca8h.jpg - 0.0045938492\n",
      "ckda5txx200093a5s16i2y97u.jpg - 0.0044944286\n",
      "ckd8u18d7000c3b5suod5aqf2.jpg - 0.0044462681\n",
      "ckda5rqvv00073a5sjxu7peen.jpg - 0.0039489269\n",
      "ckda0j24m00073a5s1oruar1e.jpg - 0.0040020943\n",
      "ckda1x6ce000s3a5sb9h33n12.jpg - 0.0038728714\n",
      "ckcbkx23f1bvd0y7m823u8lb6.jpg - 0.0037333965\n",
      "ckcblwsw91koh0y5pe2pt84hl.jpg - 0.0037324429\n",
      "ckda1f8q9000k3a5st2222ay7.jpg - 0.0038244724\n",
      "ckd8srbmv00013b5sliek3ejo.jpg - 0.0037140846\n",
      "ckcbt3uee2lwb0y7m5va0havv.jpg - 0.0036973953\n",
      "ckda9y9dd000j3a5sii08df1n.jpg - 0.0036296844\n",
      "ckda4r0w000123a5sp7v2iyem.jpg - 0.0036470890\n",
      "ckd8sun6y00063b5swzdd3fd8.jpg - 0.0037579536\n",
      "ckda5wz53000e3a5s4v8to66t.jpg - 0.0036368370\n",
      "ckcbt5sqf2kpw0y5nhh213g8i.jpg - 0.0036857128\n",
      "ckd8swai400083b5sn1693d25.jpg - 0.0037310123\n",
      "ckcbq43s523fe0y5n126g6w5h.jpg - 0.0036866665\n",
      "ckd8sv8ds00073b5scw72l1dy.jpg - 0.0037391186\n",
      "ckda0seg1000g3a5s43lgah9e.jpg - 0.0037965775\n",
      "ckda1spnc000q3a5srfxlvwce.jpg - 0.0037422180\n",
      "ckd8ttjwc00013b5s33m1jgq2.jpg - 0.0053172112\n",
      "ckcbq0gs703hv0y4h735ha581.jpg - 0.0041766167\n",
      "ckda5ue81000a3a5sqapb5u41.jpg - 0.0038266182\n",
      "ckda4mi4r000y3a5sln7mxclv.jpg - 0.0038154125\n",
      "ckda0oaty000c3a5sz6zigemv.jpg - 0.0037066936\n",
      "ckd8twk1a00063b5slocqudcl.jpg - 0.0037698746\n",
      "ckcaibt572pxu0y6fazrxcc4f.jpg - 0.0037095547\n",
      "ckda9yrip000k3a5sj7jkyh1q.jpg - 0.0037133694\n",
      "ckda9zgi9000m3a5sof671qjh.jpg - 0.0038757324\n",
      "ckd8srxq500023b5ssndncx7o.jpg - 0.0037138462\n",
      "\n",
      "Mean FPS:  258.89087435690897\n"
     ]
    }
   ],
   "source": [
    "# Set path to test dataset (Like in the instructions)\n",
    "TEST_DATASET_PATH = \"/medico2020\"\n",
    "MASK_PATH = \"/mask\"\n",
    "\n",
    "\n",
    "time_taken = []\n",
    "\n",
    "model.eval() # enter inference/evaluation mode \n",
    "for name in os.listdir(TEST_DATASET_PATH):\n",
    "    path_img = os.path.join(TEST_DATASET_PATH, name)\n",
    "        \n",
    "    img = imageio.imread(path_img) / 255\n",
    "    \n",
    "    # record shape to revert to \n",
    "    H, W, _ = img.shape\n",
    "    resize_back = transforms.Resize((H, W), interpolation=0)\n",
    "    \n",
    "    # convert to Tensors and fix the dimentions (Pytorch uses the channels in the first dimension)\n",
    "    img = torch.FloatTensor(np.transpose(img, [2, 0 ,1])).unsqueeze(0) \n",
    "    \n",
    "    # resize for the model\n",
    "    img = resize(img)\n",
    "    \n",
    "    # put on the GPU\n",
    "    img = img.to(DEVICE)\n",
    "       \n",
    "    # we do not need to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        # Start time\n",
    "        start_time = time.time()\n",
    "        ## Prediction\n",
    "        pred = model(img)\n",
    "        # End timer\n",
    "        end_time = time.time() - start_time\n",
    "\n",
    "    time_taken.append(end_time)\n",
    "    print(\"{} - {:.10f}\".format(name, end_time))\n",
    "        \n",
    "    \n",
    "    # resize back, nearest interpolation, since it's a mask\n",
    "    pred = resize_back(pred)\n",
    "    # put on cpu\n",
    "    pred = pred.cpu()\n",
    "        \n",
    "    # remove channel: BATCH x 1 x H x W => BATCH x H x W\n",
    "    pred = pred.squeeze(1)\n",
    "        \n",
    "    # comment out if your model contains a sigmoid or equivalent activation layer\n",
    "    pred = torch.sigmoid(pred)\n",
    "    # thresholding since that's how we will make predictions on new imputs\n",
    "    pred = pred > 0.5 \n",
    "    # remove BATCH => H x W\n",
    "    pred = pred.squeeze(0)\n",
    "    # converto to correct type\n",
    "    pred = pred.numpy().astype(np.float32)\n",
    "    # revert to standard intensities\n",
    "    pred = pred * 255.0\n",
    "    # save\n",
    "    pred_path = os.path.join(MASK_PATH, name)\n",
    "    cv2.imwrite(pred_path, pred)\n",
    "\n",
    "\n",
    "mean_time_taken = np.mean(time_taken)\n",
    "mean_fps = 1/mean_time_taken\n",
    "print(\"\\nMean FPS: \", mean_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
